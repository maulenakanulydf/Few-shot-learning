{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic analysis"
      ],
      "metadata": {
        "id": "NSuD2sP1RE2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DistilBERT (distilbert-base-uncased)"
      ],
      "metadata": {
        "id": "sOOYm8zszHvG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxVXiVqbzBvR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distilbert-based Multilingual Sentiment Classification Model"
      ],
      "metadata": {
        "id": "kaBD3WqH0_Wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe_1 = pipeline(\"text-classification\", model=\"tabularisai/multilingual-sentiment-analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3KY91Wz01Ew9",
        "outputId": "7764e7a1-12b9-4719-93bb-d622262a6b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Фильм оказался скучным и затянутым\"\n",
        "result = pipe_1(sentence)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3InFsqYF1TmS",
        "outputId": "bb0a8323-9253-4e78-b621-1561c3b52661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'Negative', 'score': 0.5545058846473694}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nlptown/bert-base-multilingual-uncased-sentiment"
      ],
      "metadata": {
        "id": "qZojSWzU3pNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_2 = pipeline(\"text-classification\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_6HA8DK3ri7",
        "outputId": "b68d079e-e056-4ca8-8ccc-7af93f5b5cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Этот телефон работает, как и ожидалось, без сюрпризов\"\n",
        "result = pipe_2(sentence)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRft3mRs39NW",
        "outputId": "316cec9d-fe26-4807-c2cd-ee00dfc491c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': '5 stars', 'score': 0.5823605060577393}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Seara/rubert-tiny2-russian-sentiment\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-uxyiJxN4boo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "model = pipeline(model=\"seara/rubert-tiny2-russian-sentiment\")\n",
        "model(\"я более менее отношусь к этому продукту\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StM8IN6f4f5f",
        "outputId": "fbfc0e2e-0015-4789-9def-5d4baaf9a81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'neutral', 'score': 0.6445968151092529}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jz_KikaU4vf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SetFit"
      ],
      "metadata": {
        "id": "F9dB0cPdSBP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEW FH"
      ],
      "metadata": {
        "id": "rpJPpkInl68h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C08LD_xcl9lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "vgPqIR8yt0NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TaskAdaptiveSemanticFeatureLearner(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super(TaskAdaptiveSemanticFeatureLearner, self).__init__()\n",
        "        self.base_model = AutoModel.from_pretrained(model_name)\n",
        "        self.adaptation_layer = nn.Linear(self.base_model.config.hidden_size, self.base_model.config.hidden_size)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.base_model(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        adapted_features = self.adaptation_layer(pooled_output)\n",
        "        return adapted_features"
      ],
      "metadata": {
        "id": "PUq1bKED8Vls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FewShotClassifier(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super(FewShotClassifier, self).__init__()\n",
        "        self.feature_learner = TaskAdaptiveSemanticFeatureLearner(model_name)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.feature_learner.base_model.config.hidden_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        features = self.feature_learner(input_ids, attention_mask)\n",
        "        logits = self.classifier(features)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "5bnTI2UG8aPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_embedding(model, tokenizer, texts):\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    inputs = {k: v for k, v in inputs.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "    with torch.no_grad():\n",
        "        outputs = model.feature_learner(**inputs)\n",
        "    return outputs.numpy()\n",
        "\n",
        "def few_shot_classification(model, tokenizer, support_set, query_texts):\n",
        "    category_prototypes = {}\n",
        "    for category, examples in support_set.items():\n",
        "        embeddings = get_text_embedding(model, tokenizer, examples)\n",
        "        category_prototypes[category] = np.mean(embeddings, axis=0)\n",
        "\n",
        "    for query in query_texts:\n",
        "        query_embedding = get_text_embedding(model, tokenizer, [query])[0]\n",
        "        similarities = {\n",
        "            category: cosine_similarity([query_embedding], [prototype])[0][0]\n",
        "            for category, prototype in category_prototypes.items()\n",
        "        }\n",
        "        predicted_category = max(similarities, key=similarities.get)\n",
        "        print(f\"Text: '{query}' -> Predicted Category: {predicted_category}\")"
      ],
      "metadata": {
        "id": "gLpLlxZf8dOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    model_name = \"distilbert-base-multilingual-cased\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = FewShotClassifier(model_name)\n",
        "\n",
        "    support_set = {\n",
        "        \"positive\": [\"I love this product!\", \"This is amazing!\", \"Absolutely fantastic!\"],\n",
        "        \"negative\": [\"I hate this.\", \"This is terrible.\", \"Awful experience.\"],\n",
        "        \"neutral\": [\"It's okay, not great.\", \"It's average.\", \"I feel indifferent.\"]\n",
        "    }\n",
        "\n",
        "    query_texts = [\"This is a great day!\", \"I dislike this service.\", \"более менее сервис\"]\n",
        "\n",
        "    few_shot_classification(model, tokenizer, support_set, query_texts)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "CVXBSWJq8hEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904d834a-addb-4e40-a4cb-ecb4c516f0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'This is a great day!' -> Predicted Category: positive\n",
            "Text: 'I dislike this service.' -> Predicted Category: negative\n",
            "Text: 'более менее сервис' -> Predicted Category: neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_texts = [\"This is a great day!\", \"I dislike this service.\", \"более менее сервис\"]\n",
        "\n",
        "    few_shot_classification(model, tokenizer, support_set, query_texts)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "metadata": {
        "id": "Er4vLM6K8kpg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "39b88729-c266-47c0-d355-4727be805136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-12-217e7bd72a48>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-217e7bd72a48>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    few_shot_classification(model, tokenizer, support_set, query_texts)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    }
  ]
}